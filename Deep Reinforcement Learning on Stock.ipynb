{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c6066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.serializers import save_npz,load_npz\n",
    "from plotly import tools\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import init_notebook_mode, iplot, iplot_mpl\n",
    "import plotly.express as px\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('stock_data.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.set_index('Date')\n",
    "print(data.index.min(), data.index.max())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bcaf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_split = '2020-01-01'\n",
    "start_date = '2016-01-01'\n",
    "train = data[start_date:date_split]\n",
    "test = data[date_split:]\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25937bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(train, test, date_split,ticker_name):\n",
    "    \n",
    "    data = [\n",
    "        Scatter(x=train.index, y=train[ticker_name], mode=\"lines\",name='train'),\n",
    "        Scatter(x=test.index,  y=test[ticker_name], mode=\"lines\",name='test')\n",
    "    ]\n",
    "    layout = {\n",
    "         'shapes': [\n",
    "             {'x0': date_split, 'x1': date_split, 'y0': 0, 'y1': 1, 'xref': 'x', 'yref': 'paper', 'line': {'color': 'rgb(0,0,0)', 'width': 1}}\n",
    "         ],\n",
    "        'annotations': [\n",
    "            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'left', 'text': ' test data'},\n",
    "            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'right', 'text': 'train data '}\n",
    "        ],\n",
    "        \"title\": {\"text\": ticker_name},\n",
    "    }\n",
    "    figure = Figure(data=data, layout=layout)\n",
    "    iplot(figure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test(train, test, date_split,\"EBAY\")\n",
    "# plot_train_test(train, test, date_split,\"AMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e492b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(data[start_date:], x=data[start_date:].index, y=data.columns[3:6])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9717ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \n",
    "    def __init__(self, data, history_t=90, starting_position=10000):\n",
    "        self.data = data\n",
    "        self.tickers = data.columns\n",
    "        self.history_t = history_t\n",
    "        self.starting_position = starting_position\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.t = 0\n",
    "        self.done = False\n",
    "        self.profits = 0\n",
    "        self.total_invest = 0\n",
    "        self.positions = {ticker:[] for ticker in self.tickers}\n",
    "        self.position_value = {ticker:0 for ticker in self.tickers}\n",
    "        self.history = {ticker:[0 for _ in range(self.history_t)] for ticker in self.tickers}\n",
    "        return {ticker:[self.position_value[ticker]] + self.history[ticker] for ticker in self.tickers} # obs\n",
    "    \n",
    "    def step(self, act):\n",
    "        reward = 0\n",
    "        \n",
    "        # act = 0: stay, 1: buy, 2: sell\n",
    "        for ticker in self.tickers:\n",
    "            if act[ticker] == 1: # buy\n",
    "                if self.data.iloc[self.t, :][ticker] < (self.starting_position - self.total_invest): # have enough money\n",
    "                    self.positions[ticker].append(self.data.iloc[self.t, :][ticker])\n",
    "                    self.total_invest += self.data.iloc[self.t, :][ticker]\n",
    "                else:\n",
    "                    reward += -1\n",
    "            elif act[ticker] == 2: # sell\n",
    "                if len(self.positions[ticker]) == 0:\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    profits = 0\n",
    "                    for p in self.positions[ticker]:\n",
    "                        profits += (self.data.iloc[self.t, :][ticker] - p)\n",
    "                        self.total_invest -= self.data.iloc[self.t, :][ticker]\n",
    "                    reward += profits\n",
    "                    self.profits += profits\n",
    "                    self.positions[ticker] = []\n",
    "        \n",
    "        # set next time\n",
    "        self.t += 1\n",
    "        for ticker in self.tickers: \n",
    "            self.position_value[ticker] = 0\n",
    "            for p in self.positions[ticker]:\n",
    "                self.position_value[ticker] += (self.data.iloc[self.t, :][ticker] - p)\n",
    "            self.history[ticker].pop(0)\n",
    "            self.history[ticker].append(self.data.iloc[self.t, :][ticker] - self.data.iloc[(self.t-1), :][ticker])\n",
    "        \n",
    "        # clipping reward\n",
    "        if reward > 0:\n",
    "            reward = 1\n",
    "        elif reward < 0:\n",
    "            reward = -1\n",
    "        \n",
    "        return {ticker:[self.position_value[ticker]] + self.history[ticker] for ticker in self.tickers}, reward, self.done # obs, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85dbee3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DLTR': [0, 0, 0, 0, 0], 'BKNG': [0, 0, 0, 0, 0], 'CTSH': [0, 0, 0, 0, 0], 'VRTX': [0, 0, 0, 0, 0], 'FISV': [0, 0, 0, 0, 0], 'AMD': [0, 0, 0, 0, 0], 'ADP': [0, 0, 0, 0, 0], 'CSX': [0, 0, 0, 0, 0], 'EBAY': [0, 0, 0, 0, 0], 'WBA': [0, 0, 0, 0, 0], 'EXC': [0, 0, 0, 0, 0]}\n",
      "{'DLTR': 1, 'BKNG': 1, 'CTSH': 1, 'VRTX': 0, 'FISV': 1, 'AMD': 0, 'ADP': 0, 'CSX': 0, 'EBAY': 2, 'WBA': 1, 'EXC': 2}\n",
      "({'DLTR': [1.1700057983398438, 0, 0, 0, 1.1700057983398438], 'BKNG': [-34.6800537109375, 0, 0, 0, -34.6800537109375], 'CTSH': [0.0, 0, 0, 0, 0.0], 'VRTX': [0, 0, 0, 0, 0.5599975585937642], 'FISV': [0.2050018310546875, 0, 0, 0, 0.2050018310546875], 'AMD': [0, 0, 0, 0, -0.019999980926513672], 'ADP': [0, 0, 0, 0, 0.1999969482421875], 'CSX': [0, 0, 0, 0, -0.08666706085205078], 'EBAY': [0, 0, 0, 0, -0.3099994659423828], 'WBA': [-2.1800003051757812, 0, 0, 0, -2.1800003051757812], 'EXC': [0, 0, 0, 0, 0.13552093505859375]}, -1, False)\n",
      "{'DLTR': 1, 'BKNG': 1, 'CTSH': 2, 'VRTX': 1, 'FISV': 1, 'AMD': 1, 'ADP': 2, 'CSX': 2, 'EBAY': 0, 'WBA': 2, 'EXC': 0}\n",
      "({'DLTR': [2.2499923706054688, 0, 0, 1.1700057983398438, 0.5399932861328125], 'BKNG': [-62.6400146484375, 0, 0, -34.6800537109375, -13.97998046875], 'CTSH': [0, 0, 0, 0.0, -1.0], 'VRTX': [-1.219993591308608, 0, 0, 0.5599975585937642, -1.219993591308608], 'FISV': [-0.47499847412109375, 0, 0, 0.2050018310546875, -0.3400001525878906], 'AMD': [-0.24000000953674316, 0, 0, -0.019999980926513672, -0.24000000953674316], 'ADP': [0, 0, 0, 0.1999969482421875, -1.0099945068359375], 'CSX': [0, 0, 0, -0.08666706085205078, -0.38666725158691406], 'EBAY': [0, 0, 0, -0.3099994659423828, 0.28999900817871094], 'WBA': [0, 0, 0, -2.1800003051757812, -1.2400054931640625], 'EXC': [0, 0, 0, 0.13552093505859375, 0.021398544311523438]}, -1, False)\n",
      "{'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 0, 'AMD': 2, 'ADP': 0, 'CSX': 0, 'EBAY': 1, 'WBA': 0, 'EXC': 1}\n",
      "({'DLTR': [-1.8900070190429688, 0, 1.1700057983398438, 0.5399932861328125, -2.0699996948242188], 'BKNG': [-121.6800537109375, 0, -34.6800537109375, -13.97998046875, -29.52001953125], 'CTSH': [0, 0, 0.0, -1.0, -0.4900016784667969], 'VRTX': [-8.489997863769545, 0, 0.5599975585937642, -1.219993591308608, -7.2700042724609375], 'FISV': [-1.4950027465820312, 0, 0.2050018310546875, -0.3400001525878906, -0.5100021362304688], 'AMD': [0, 0, -0.019999980926513672, -0.24000000953674316, -0.23000001907348633], 'ADP': [0, 0, 0.1999969482421875, -1.0099945068359375, -2.4800033569335938], 'CSX': [0, 0, -0.08666706085205078, -0.38666725158691406, -0.25], 'EBAY': [-0.7199993133544922, 0, -0.3099994659423828, 0.28999900817871094, -0.7199993133544922], 'WBA': [0, 0, -2.1800003051757812, -1.2400054931640625, 1.5400009155273438], 'EXC': [-0.24964332580566406, 0, 0.13552093505859375, 0.021398544311523438, -0.24964332580566406]}, -1, False)\n"
     ]
    }
   ],
   "source": [
    "# naive agent\n",
    "env = Environment1(train,history_t=4)\n",
    "print(env.reset())\n",
    "for _ in range(3):\n",
    "    pact = {ticker:np.random.randint(3) for ticker in train.columns}\n",
    "    print(pact)\n",
    "    print(env.step(pact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ae2ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dueling Double DQN\n",
    "\n",
    "class Q_Network(chainer.Chain):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, N):\n",
    "        super(Q_Network, self).__init__(\n",
    "            fc1 = L.Linear(input_size, hidden_size),\n",
    "            fc2 = L.Linear(hidden_size, hidden_size),\n",
    "            fc3 = L.Linear(hidden_size, hidden_size),\n",
    "            fc4 = L.Linear(hidden_size, hidden_size//2),\n",
    "            fc5 = L.Linear(hidden_size, hidden_size//2),\n",
    "            state_value = L.Linear(hidden_size//2, N),\n",
    "            advantage_value = L.Linear(hidden_size//2, output_size*N)\n",
    "        )\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.N = N\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = F.relu(self.fc3(h))\n",
    "        hs = F.relu(self.fc4(h))\n",
    "        ha = F.relu(self.fc5(h))\n",
    "        state_value = self.state_value(hs) # [50,11]\n",
    "        advantage_value = self.advantage_value(ha).reshape(-1,self.N,self.output_size) # [50,11,3]\n",
    "        advantage_mean = (F.sum(advantage_value, axis=2)/float(self.output_size)).reshape(-1, self.N) # [50,11]\n",
    "        state_value_reshape = F.concat([state_value for _ in range(self.output_size)], axis=1).reshape(-1,self.N,self.output_size)\n",
    "        advantage_mean_reshape = F.concat([advantage_mean for _ in range(self.output_size)], axis=1).reshape(-1,self.N,self.output_size)\n",
    "        q_value = state_value_reshape - advantage_value - advantage_mean_reshape\n",
    "        return q_value\n",
    "\n",
    "    def reset(self):\n",
    "        self.zerograds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a6d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69a51706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_by_q(train_env, test_env, Q):\n",
    "    \n",
    "    print(\"Runing training data...\")\n",
    "    pobs = train_env.reset()\n",
    "    train_acts = []\n",
    "    train_rewards = []\n",
    "\n",
    "    for _ in range(len(train_env.data)-1):\n",
    "        \n",
    "        if _%365 == 0:\n",
    "            print(\"Now on date: \",str(train_env.data.index[_]))\n",
    "            print(\"Profits so far:\", train_env.profits)\n",
    "            print(\"Last Rewards:\", train_rewards[-5:])\n",
    "            print(\"How much in?\", {ticker:sum(positions) for ticker,positions in train_env.positions.items()})\n",
    "            print(\"Sum\", sum([sum(positions) for positions in train_env.positions.values()]))\n",
    "            \n",
    "        \n",
    "        pact = Q(np.array(list(pobs.values()), dtype=np.float32).reshape(1,-1)).reshape(N,3)\n",
    "        pact = np.argmax(pact.data, axis=1)\n",
    "        pact = {ticker:act for ticker,act in zip(env.data.columns,pact)}\n",
    "        train_acts.append(pact)\n",
    "        \n",
    "        profits_before = train_env.profits\n",
    "            \n",
    "        obs, reward, done = train_env.step(pact)\n",
    "        train_rewards.append(reward)\n",
    "\n",
    "        pobs = obs\n",
    "        \n",
    "        profits_after = train_env.profits\n",
    "        \n",
    "        if profits_after-profits_before > 100:\n",
    "            print(pact)\n",
    "            print(\"profits_before\",profits_before)\n",
    "            print(\"profits_after\",profits_after)\n",
    "            print(\"date:\", str(train_env.data.index[_]))\n",
    "            print(\"How much in?\", {ticker:sum(positions) for ticker,positions in train_env.positions.items()})\n",
    "            print(\"Sum\", sum([sum(positions) for positions in train_env.positions.values()]))\n",
    "            print(\"reward\",reward)\n",
    "        \n",
    "    train_profits = train_env.profits\n",
    "    \n",
    "    print(\"Runing test data...\")\n",
    "    pobs = test_env.reset()\n",
    "    test_acts = []\n",
    "    test_rewards = []\n",
    "\n",
    "    for _ in range(len(test_env.data)-1):\n",
    "        \n",
    "        if _%100 == 0:\n",
    "            print(\"Now on date: \",str(test_env.data.index[_]))\n",
    "            print(\"Profits so far:\", test_env.profits)\n",
    "            print(\"Last Rewards:\", test_rewards[-5:])\n",
    "            print(\"How much in?\", {ticker:sum(positions) for ticker,positions in test_env.positions.items()})\n",
    "            print(\"Sum\", sum([sum(positions) for positions in test_env.positions.values()]))\n",
    "    \n",
    "        pact = Q(np.array(list(pobs.values()), dtype=np.float32).reshape(1,-1)).reshape(N,3)\n",
    "        pact = np.argmax(pact.data, axis=1)\n",
    "        pact = {ticker:act for ticker,act in zip(env.data.columns,pact)}\n",
    "        test_acts.append(pact)\n",
    "            \n",
    "        obs, reward, done = test_env.step(pact)\n",
    "        test_rewards.append(reward)\n",
    "\n",
    "        pobs = obs\n",
    "        \n",
    "    test_profits = test_env.profits\n",
    "    \n",
    "    return train_rewards, train_profits, test_rewards, test_profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57196e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\t\tepsilon\t\tlog_reward\t\tlog_loss\t\tprofits\t\ttotal_invest\t\telapsed_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10908/1178153048.py:79: DeprecationWarning:\n",
      "\n",
      "`np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.9919600000000366\t-696.0\t353.5906059592962\t159.6025760173776\t8409.576512575151\t21.810511827468872\n",
      "2\t0.9819100000000823\t-775.0\t1020.193588450551\t3017.483112335205\t-1101.2897605895996\t32.422977685928345\n",
      "3\t0.9718600000001281\t-779.0\t1237.8937463462353\t1298.632668495179\t735.091494560241\t29.233184814453125\n",
      "4\t0.9618100000001738\t-833.0\t1359.1212265193462\t1306.1199312210067\t10030.080149650576\t32.16288113594055\n",
      "5\t0.9517600000002195\t-863.0\t1022.6845187842846\t6749.659621477124\t10058.97022891045\t31.116665601730347\n",
      "6\t0.9417100000002653\t-833.0\t860.4015000760555\t9204.584937095638\t10013.82495594025\t31.775076389312744\n",
      "7\t0.931660000000311\t-753.0\t1861.9803243279457\t14074.468946576117\t-4186.072239041327\t36.498414754867554\n",
      "8\t0.9216100000003568\t-752.0\t1167.1433885991573\t5481.521406531334\t4314.761642098427\t35.224907875061035\n",
      "9\t0.9115600000004025\t-665.0\t593.2996732592583\t4622.020439267159\t6796.409847140311\t35.2990608215332\n",
      "10\t0.9015100000004482\t-644.0\t217.79697972536087\t3552.3838019371037\t4655.248968601227\t35.86848497390747\n",
      "11\t0.891460000000494\t-752.0\t420.0406426936388\t5415.679650425911\t965.0203465223312\t35.11025595664978\n",
      "12\t0.8814100000005397\t-845.0\t600.3312114030123\t1793.3192812204372\t9858.750756621359\t38.53658747673035\n",
      "13\t0.8713600000005854\t-823.0\t579.6418198496103\t3878.2861863374706\t431.2238196134572\t36.52435326576233\n",
      "14\t0.8613100000006312\t-853.0\t500.01900164783\t3920.9287040233603\t946.5312988758096\t34.572838306427\n",
      "15\t0.8512600000006769\t-725.0\t419.4512588977814\t7889.1511014699945\t-4402.241090178491\t38.37499380111694\n",
      "16\t0.8412100000007227\t-837.0\t284.6721874475479\t4631.859573960302\t9874.069016814234\t35.73208689689636\n",
      "17\t0.8311600000007684\t-857.0\t289.57702423632145\t5381.800057530403\t-1247.0000544786453\t36.193103551864624\n",
      "18\t0.8211100000008141\t-773.0\t323.2534288018942\t5737.899086117744\t190.98092257976532\t37.198678970336914\n",
      "19\t0.8110600000008599\t-791.0\t278.43998512625694\t3628.734210848809\t8705.025840878487\t37.39464545249939\n",
      "20\t0.8010100000009056\t-774.0\t214.70560393482447\t4204.773183226585\t-387.87984597682953\t33.230743408203125\n",
      "21\t0.7909600000009513\t-841.0\t314.7519657611847\t5105.6012486219415\t10028.688782811165\t40.58137607574463\n",
      "22\t0.7809100000009971\t-841.0\t227.2984996959567\t5600.9898426532745\t5715.247786283493\t38.62338423728943\n",
      "23\t0.7708600000010428\t-818.0\t273.3369713500142\t3872.982138991353\t9989.067837357525\t40.09471607208252\n",
      "24\t0.7608100000010886\t-845.0\t246.57894523441792\t5555.865591287613\t10034.194509267807\t34.28755736351013\n",
      "25\t0.7507600000011343\t-862.0\t300.09578880667686\t9727.508408427237\t9985.93251335621\t34.22028160095215\n",
      "26\t0.74071000000118\t-810.0\t260.52181074023247\t7565.155631422996\t-1444.5956338644019\t44.197211265563965\n",
      "27\t0.7306600000012258\t-798.0\t157.77524677664042\t5103.295188069343\t9249.424710154533\t37.243255376815796\n",
      "28\t0.7206100000012715\t-837.0\t254.47562887519598\t6302.411357164379\t10152.585049390796\t33.625333309173584\n",
      "29\t0.7105600000013172\t-843.0\t242.1081359088421\t5619.209474205969\t9802.161196112635\t33.121785163879395\n",
      "30\t0.700510000001363\t-860.0\t248.58819638192654\t5889.386914134026\t8087.493109822273\t37.15646290779114\n",
      "31\t0.6904600000014087\t-869.0\t181.81179493665695\t6697.424860596657\t-2074.792696595192\t41.7504403591156\n",
      "32\t0.6804100000014545\t-863.0\t169.7006560191512\t5939.815229296684\t4389.987991452217\t32.68390250205994\n",
      "33\t0.6703600000015002\t-813.0\t133.9913636147976\t4924.318473696709\t4782.961517453194\t42.02134728431702\n",
      "34\t0.6603100000015459\t-913.0\t206.74152380228043\t7222.308378458022\t-1180.2091772556296\t46.46581196784973\n",
      "35\t0.6502600000015917\t-917.0\t238.48916574567556\t4781.759324431419\t10035.403349518776\t45.94907999038696\n",
      "36\t0.6402100000016374\t-925.0\t236.2419333383441\t3033.7372683286662\t9116.672769665718\t42.20921349525452\n",
      "37\t0.6301600000016832\t-875.0\t219.4389412999153\t2170.7605789899817\t4114.389412999154\t38.53116965293884\n",
      "38\t0.6201100000017289\t-772.0\t159.17717862129211\t4979.566162467002\t6813.124160408975\t39.750821113586426\n",
      "39\t0.6100600000017746\t-855.0\t121.06732746958733\t5695.630732536314\t8846.94641017914\t40.31197214126587\n",
      "40\t0.6000100000018204\t-866.0\t107.82831133529544\t5686.812141537668\t7339.442428469656\t38.48240780830383\n",
      "41\t0.5899600000018661\t-781.0\t114.75567363202572\t6639.98894882202\t10031.851057052614\t43.779608726501465\n",
      "42\t0.5799100000019118\t-788.0\t110.73433115333319\t8273.733820796011\t4923.186562657358\t37.14952349662781\n",
      "43\t0.5698600000019576\t-894.0\t132.97488946467638\t8135.371871352194\t10098.24805891514\t33.12224340438843\n",
      "44\t0.5598100000020033\t-876.0\t120.96278100088239\t8207.031087517738\t2533.973917365074\t39.8632378578186\n",
      "45\t0.549760000002049\t-875.0\t119.5106511078775\t4661.642319440842\t10115.7576649189\t40.92148780822754\n",
      "46\t0.5397100000020948\t-899.0\t188.12262282893062\t9297.385205745697\t8199.055943012238\t40.348973512649536\n",
      "47\t0.5296600000021405\t-809.0\t131.50371034443378\t5199.34110045433\t3770.6989176273346\t45.14206600189209\n",
      "48\t0.5196100000021863\t-847.0\t118.29006303101778\t7779.661110758781\t8877.22891151905\t47.261576652526855\n",
      "49\t0.509560000002232\t-760.0\t121.32511179894209\t7058.432317376136\t6460.638292670251\t37.14894938468933\n",
      "50\t0.499510000002275\t-767.0\t88.46515340730548\t8980.43718969822\t5670.296912550926\t39.40453052520752\n",
      "51\t0.48946000000226497\t-861.0\t149.56336024403572\t6518.109255552293\t7460.5007412433615\t41.650936126708984\n",
      "52\t0.4794100000022549\t-835.0\t152.13674081116915\t9088.834400534626\t5505.585597634319\t47.3094379901886\n",
      "53\t0.46936000000224487\t-836.0\t99.5936658680439\t3009.2877106666565\t6318.294238567352\t41.4699604511261\n",
      "54\t0.4593100000022348\t-902.0\t127.96633131429553\t8475.269415855408\t-2257.089409828186\t41.854992628097534\n",
      "55\t0.44926000000222477\t-828.0\t115.78214511275291\t3515.464849114416\t9989.765301108362\t38.514527559280396\n",
      "56\t0.4392100000022147\t-902.0\t107.17178507894278\t11918.358262896538\t10018.251855969429\t42.10728931427002\n",
      "57\t0.42916000000220467\t-853.0\t81.09267667680979\t6692.436439275739\t10078.073610544208\t43.64334964752197\n",
      "58\t0.4191100000021946\t-883.0\t83.67236150056124\t3897.167894244193\t9996.892252087593\t36.7789580821991\n",
      "59\t0.40906000000218457\t-917.0\t124.95106136798859\t12414.90118098259\t9999.60882115364\t39.83466625213623\n",
      "60\t0.3990100000021745\t-877.0\t147.95371358841658\t10245.18605184555\t7202.884039402008\t44.383583784103394\n",
      "61\t0.38896000000216446\t-927.0\t127.78649873286486\t5459.519177913665\t9987.20083284378\t50.566267013549805\n",
      "62\t0.3789100000021544\t-921.0\t133.54241201654077\t4657.841593027113\t9707.732219457628\t38.36197900772095\n",
      "63\t0.36886000000214436\t-921.0\t139.24426276236773\t6115.144774079323\t10016.165202498436\t46.560086488723755\n",
      "64\t0.3588100000021343\t-927.0\t121.24811693280935\t12413.48827922344\t-3659.7982729673367\t43.70637035369873\n",
      "65\t0.34876000000212426\t-903.0\t88.38709478452802\t6387.920339941978\t9244.249663949013\t41.36828279495239\n",
      "66\t0.3387100000021142\t-945.0\t97.7924087010324\t6841.746384978294\t7947.030312180519\t36.44857120513916\n",
      "67\t0.32866000000210416\t-896.0\t89.73004446178675\t7524.856998562812\t-4349.172315716743\t47.885621309280396\n",
      "68\t0.3186100000020941\t-913.0\t76.50674659013748\t9800.487671494484\t4127.03574693203\t38.84599995613098\n",
      "69\t0.30856000000208406\t-943.0\t72.93172167614102\t3885.704241871833\t9492.415760874748\t34.252230405807495\n",
      "70\t0.298510000002074\t-935.0\t77.95240584015846\t7113.806025862694\t10017.47736799717\t44.2568793296814\n",
      "71\t0.28846000000206395\t-897.0\t86.74560809880495\t10764.988670110699\t-904.2019746303522\t43.51675200462341\n",
      "72\t0.2784100000020539\t-923.0\t86.78906242921948\t2504.84239256382\t8992.327618956566\t48.550641775131226\n",
      "73\t0.26836000000204385\t-939.0\t197.73734363168478\t14113.701638936995\t4683.558367013933\t46.93277883529663\n",
      "74\t0.2583100000020338\t-931.0\t117.38683348894119\t7947.455903410912\t7913.043545365334\t48.97851276397705\n",
      "75\t0.24826000000202375\t-932.0\t83.11757267639041\t5770.210572004318\t10051.479466676712\t54.76861214637756\n",
      "76\t0.2382100000020137\t-944.0\t89.29256258904934\t7509.163922190666\t10033.081057667732\t63.23962759971619\n",
      "77\t0.22816000000200365\t-941.0\t84.64581131190062\t7679.981377720833\t4896.047549128532\t50.235095500946045\n",
      "78\t0.2181100000019936\t-953.0\t68.88666281476617\t7094.3465069532385\t9997.113473057747\t39.34202432632446\n",
      "79\t0.20806000000198355\t-955.0\t79.82195513136685\t8290.883818030357\t10025.556323647499\t47.81472134590149\n",
      "80\t0.1980100000019735\t-965.0\t73.2518662288785\t3032.9241402149164\t10137.165858030323\t45.016257762908936\n",
      "81\t0.18796000000196345\t-959.0\t70.60603048838675\t6928.260434269905\t9995.579756617546\t42.79163074493408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\t0.1779100000019534\t-945.0\t52.052133712917566\t11079.120793938635\t9638.892538428308\t43.65379023551941\n",
      "83\t0.16786000000194334\t-961.0\t92.42128460854292\t11211.40221464634\t6341.587821364403\t59.03050637245178\n",
      "84\t0.1578100000019333\t-952.0\t172.55951770022511\t5209.163728833199\t10051.800203204155\t56.79376482963562\n",
      "85\t0.14776000000192324\t-971.0\t89.55159099027514\t8442.460577845573\t10032.399256825447\t51.627121925354004\n",
      "86\t0.1377100000019132\t-970.0\t67.465286411345\t4528.671954035759\t10010.858130574226\t46.937116622924805\n",
      "87\t0.12766000000190314\t-969.0\t53.38370597921312\t10039.20580291748\t7915.130873680115\t43.91768741607666\n",
      "88\t0.11761000000190334\t-942.0\t76.61307282373309\t10556.525907516478\t9976.660776138307\t51.156524896621704\n",
      "89\t0.10756000000190724\t-989.0\t66.195281567052\t4478.017648696899\t10062.07736980915\t57.06883668899536\n",
      "90\t0.09999000000191018\t-968.0\t64.31526703946292\t7456.146258831023\t9647.823744297028\t50.32973289489746\n"
     ]
    }
   ],
   "source": [
    "# def train_dddqn(env):\n",
    "\n",
    "env = Environment1(train,history_t=90)\n",
    "env.reset()\n",
    "N = len(env.data.columns)\n",
    "\n",
    "Q = Q_Network(input_size=(env.history_t+1)*N, hidden_size=256, output_size=3,N=N)\n",
    "Q_ast = copy.deepcopy(Q)\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(Q)\n",
    "\n",
    "with open('log.txt', 'w') as the_file:\n",
    "    the_file.write('\\t\\t'.join(map(str, [\"epoch\", \"epsilon\", \"log_reward\", \"log_loss\", \"profits\", \"total_invest\",\"elapsed_time\"])))\n",
    "    the_file.write(\"\\n\")\n",
    "print('\\t\\t'.join(map(str, [\"epoch\", \"epsilon\", \"log_reward\", \"log_loss\", \"profits\", \"total_invest\",\"elapsed_time\"])))\n",
    "\n",
    "epoch_num = 100\n",
    "step_max = len(env.data)-1\n",
    "memory_size = 200\n",
    "batch_size = 50\n",
    "epsilon = 1.0\n",
    "epsilon_decrease = 1e-5\n",
    "epsilon_min = 0.1\n",
    "start_reduce_epsilon = 200\n",
    "train_freq = 10\n",
    "update_q_freq = 20\n",
    "gamma = 0.97\n",
    "show_log_freq = 1\n",
    "\n",
    "memory = []\n",
    "total_step = 0\n",
    "total_rewards = []\n",
    "total_losses = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(epoch_num):\n",
    "\n",
    "    pobs = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    while not done and step < step_max:\n",
    "        \n",
    "        # select act\n",
    "        if len(memory) != memory_size:\n",
    "            pact = {ticker:np.random.randint(3) for ticker in env.data.columns}\n",
    "        else:\n",
    "            pact = Q(np.array(list(pobs.values()), dtype=np.float32).reshape(1,-1)).reshape(N,3)\n",
    "            pact = np.argmax(pact.data, axis=1)\n",
    "            pact = {ticker:act for ticker,act in zip(env.data.columns,pact)}\n",
    "            if np.random.rand() < epsilon:\n",
    "                random_ticker = env.data.columns[np.random.randint(N)]\n",
    "                pact[random_ticker] = np.random.randint(3)\n",
    "\n",
    "        # act\n",
    "        obs, reward, done = env.step(pact)\n",
    "        \n",
    "        # add memory\n",
    "        memory.append((pobs, pact, reward, obs, done))\n",
    "        if len(memory) > memory_size:\n",
    "            memory.pop(0)\n",
    "            \n",
    "        # train or update q\n",
    "        if len(memory) == memory_size:\n",
    "            if total_step % train_freq == 0:\n",
    "                shuffled_memory = np.random.permutation(memory)\n",
    "                memory_idx = range(len(shuffled_memory))\n",
    "                for i in memory_idx[::batch_size]:\n",
    "                    batch = np.array(shuffled_memory[i:i+batch_size])\n",
    "                    b_pobs = [list(batch[:, 0][i].values()) for i in range(len(batch[:, 0]))]\n",
    "                    b_pobs = np.array(b_pobs, dtype=np.float32)\n",
    "                    b_pact = [list(batch[:, 1][i].values()) for i in range(len(batch[:, 0]))]\n",
    "                    b_pact = np.array(b_pact, dtype=int)\n",
    "                    b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n",
    "                    b_obs = [list(batch[:, 3][i].values()) for i in range(len(batch[:, 0]))]\n",
    "                    b_obs = np.array(b_obs, dtype=np.float32)\n",
    "                    b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)\n",
    "                    \n",
    "                    q = Q(b_pobs)\n",
    "                    indices = np.argmax(q.data, axis=2) # [50,11]\n",
    "                    maxqs = Q_ast(b_obs).data\n",
    "                    target = copy.deepcopy(q.data)\n",
    "                    for j in range(batch_size):\n",
    "                        target[j, b_pact[j]] = b_reward[j]+gamma*maxqs[j, indices[j]]*(not b_done[j])\n",
    "                    \n",
    "                    Q.reset()\n",
    "                    loss = F.mean_squared_error(q, target)\n",
    "                    total_loss += loss.data\n",
    "                    loss.backward()\n",
    "                    optimizer.update()\n",
    "                \n",
    "            if total_step % update_q_freq == 0:\n",
    "                Q_ast = copy.deepcopy(Q)\n",
    "                    \n",
    "        if epsilon > epsilon_min and total_step > start_reduce_epsilon:\n",
    "            epsilon -= epsilon_decrease\n",
    "        \n",
    "        # next step\n",
    "        total_reward += reward\n",
    "        pobs = obs\n",
    "        step += 1\n",
    "        total_step += 1\n",
    "        \n",
    "    total_rewards.append(total_reward)\n",
    "    total_losses.append(total_loss)\n",
    "    \n",
    "    if (epoch+1) % show_log_freq == 0:\n",
    "        log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq\n",
    "        log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq\n",
    "        elapsed_time = time.time()-start\n",
    "        print('\\t'.join(map(str, [epoch+1, epsilon, log_reward, log_loss, env.profits, env.total_invest ,elapsed_time])))\n",
    "        with open('log.txt', 'a') as the_file:\n",
    "            the_file.write('\\t'.join(map(str, [epoch+1, epsilon, log_reward, log_loss, env.profits , env.total_invest ,elapsed_time])))\n",
    "            the_file.write('\\n')\n",
    "        start = time.time()\n",
    "        save_npz('my.model', Q)\n",
    "\n",
    "print(\"total_losses\",total_losses)\n",
    "print(\"total_rewards\",total_rewards)\n",
    "save_npz('my.model', Q)\n",
    "\n",
    "with open('log.txt', 'a') as the_file:\n",
    "    the_file.write(\"Total Losses: \")\n",
    "    the_file.write(str(total_losses))\n",
    "    the_file.write(\"Total Rewards: \")\n",
    "    the_file.write(str(total_rewards))    \n",
    "\n",
    "                   \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b01725de",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment1(train,history_t=90)\n",
    "env.reset()\n",
    "N = len(env.data.columns)\n",
    "\n",
    "Q = Q_Network(input_size=(env.history_t+1)*N, hidden_size=256, output_size=3,N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e3ced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_npz(\"./my.model\",Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd9ea8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing training data...\n",
      "Now on date:  2016-01-04 00:00:00\n",
      "Profits so far: 0\n",
      "Last Rewards: []\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 0, 'AMD': 0, 'ADP': 0, 'CSX': 0, 'EBAY': 0, 'WBA': 0, 'EXC': 0}\n",
      "Sum 0\n",
      "{'DLTR': 2, 'BKNG': 2, 'CTSH': 1, 'VRTX': 0, 'FISV': 1, 'AMD': 1, 'ADP': 2, 'CSX': 0, 'EBAY': 1, 'WBA': 0, 'EXC': 0}\n",
      "profits_before 28.869983673095703\n",
      "profits_after 4209.539661407471\n",
      "date: 2017-03-07 00:00:00\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 1268.2299995422363, 'AMD': 84.46999883651733, 'ADP': 0, 'CSX': 0, 'EBAY': 680.4500045776367, 'WBA': 0, 'EXC': 19.950071334838867}\n",
      "Sum 2053.1000742912292\n",
      "reward 1\n",
      "Now on date:  2017-06-15 00:00:00\n",
      "Profits so far: 4209.539661407471\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 10551.25, 'CTSH': 0, 'VRTX': 0, 'FISV': 2144.2049980163574, 'AMD': 305.3399968147278, 'ADP': 0, 'CSX': 0, 'EBAY': 1179.8500061035156, 'WBA': 0, 'EXC': 19.950071334838867}\n",
      "Sum 14200.59507226944\n",
      "{'DLTR': 2, 'BKNG': 2, 'CTSH': 1, 'VRTX': 0, 'FISV': 1, 'AMD': 1, 'ADP': 2, 'CSX': 0, 'EBAY': 1, 'WBA': 0, 'EXC': 0}\n",
      "profits_before 4209.539661407471\n",
      "profits_after 6687.229602813721\n",
      "date: 2018-03-16 00:00:00\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 2144.2049980163574, 'AMD': 305.3399968147278, 'ADP': 0, 'CSX': 0, 'EBAY': 1179.8500061035156, 'WBA': 0, 'EXC': 19.950071334838867}\n",
      "Sum 3649.3450722694397\n",
      "reward 1\n",
      "{'DLTR': 2, 'BKNG': 2, 'CTSH': 1, 'VRTX': 0, 'FISV': 1, 'AMD': 1, 'ADP': 2, 'CSX': 0, 'EBAY': 1, 'WBA': 0, 'EXC': 0}\n",
      "profits_before 6277.589267730713\n",
      "profits_after 6456.309238433838\n",
      "date: 2018-09-04 00:00:00\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 75.63999938964844, 'VRTX': 0, 'FISV': 6222.2949867248535, 'AMD': 1189.4199976921082, 'ADP': 0, 'CSX': 0, 'EBAY': 3155.360023498535, 'WBA': 0, 'EXC': 19.950071334838867}\n",
      "Sum 10662.665078639984\n",
      "reward 1\n",
      "{'DLTR': 2, 'BKNG': 2, 'CTSH': 1, 'VRTX': 0, 'FISV': 1, 'AMD': 1, 'ADP': 2, 'CSX': 0, 'EBAY': 1, 'WBA': 0, 'EXC': 0}\n",
      "profits_before 6399.169094085693\n",
      "profits_after 6517.809108734131\n",
      "date: 2018-09-24 00:00:00\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 77.2699966430664, 'VRTX': 0, 'FISV': 7348.944980621338, 'AMD': 1618.92999792099, 'ADP': 0, 'CSX': 0, 'EBAY': 3632.3000259399414, 'WBA': 0, 'EXC': 19.950071334838867}\n",
      "Sum 12697.395072460175\n",
      "reward 1\n",
      "Now on date:  2018-11-26 00:00:00\n",
      "Profits so far: 6482.399143218994\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 9570.644985198975, 'AMD': 2358.1199984550476, 'ADP': 0, 'CSX': 0, 'EBAY': 4527.220031738281, 'WBA': 0, 'EXC': 19.950071334838867}\n",
      "Sum 16475.935086727142\n",
      "Runing test data...\n",
      "Now on date:  2020-01-02 00:00:00\n",
      "Profits so far: 0\n",
      "Last Rewards: []\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 0, 'AMD': 0, 'ADP': 0, 'CSX': 0, 'EBAY': 0, 'WBA': 0, 'EXC': 0}\n",
      "Sum 0\n",
      "Now on date:  2020-05-27 00:00:00\n",
      "Profits so far: -1564.4974594116213\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 4624.710014343262, 'AMD': 2212.92000579834, 'ADP': 0, 'CSX': 0, 'EBAY': 1621.4200038909912, 'WBA': 0, 'EXC': 0}\n",
      "Sum 8459.050024032593\n",
      "Now on date:  2020-10-16 00:00:00\n",
      "Profits so far: -1564.4974594116213\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 4624.710014343262, 'AMD': 2212.92000579834, 'ADP': 0, 'CSX': 0, 'EBAY': 1621.4200038909912, 'WBA': 0, 'EXC': 0}\n",
      "Sum 8459.050024032593\n",
      "Now on date:  2021-03-12 00:00:00\n",
      "Profits so far: -1564.4974594116213\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 4624.710014343262, 'AMD': 2212.92000579834, 'ADP': 0, 'CSX': 0, 'EBAY': 1621.4200038909912, 'WBA': 0, 'EXC': 0}\n",
      "Sum 8459.050024032593\n",
      "Now on date:  2021-08-04 00:00:00\n",
      "Profits so far: -1564.4974594116213\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 4624.710014343262, 'AMD': 2212.92000579834, 'ADP': 0, 'CSX': 0, 'EBAY': 1621.4200038909912, 'WBA': 0, 'EXC': 0}\n",
      "Sum 8459.050024032593\n",
      "Now on date:  2021-12-27 00:00:00\n",
      "Profits so far: -1564.4974594116213\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 4624.710014343262, 'AMD': 2212.92000579834, 'ADP': 0, 'CSX': 0, 'EBAY': 1621.4200038909912, 'WBA': 0, 'EXC': 0}\n",
      "Sum 8459.050024032593\n",
      "Now on date:  2022-05-19 00:00:00\n",
      "Profits so far: -1564.4974594116213\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 4624.710014343262, 'AMD': 2212.92000579834, 'ADP': 0, 'CSX': 0, 'EBAY': 1621.4200038909912, 'WBA': 0, 'EXC': 0}\n",
      "Sum 8459.050024032593\n",
      "Now on date:  2022-10-12 00:00:00\n",
      "Profits so far: -1564.4974594116213\n",
      "Last Rewards: [-1, -1, -1, -1, -1]\n",
      "How much in? {'DLTR': 0, 'BKNG': 0, 'CTSH': 0, 'VRTX': 0, 'FISV': 4624.710014343262, 'AMD': 2212.92000579834, 'ADP': 0, 'CSX': 0, 'EBAY': 1621.4200038909912, 'WBA': 0, 'EXC': 0}\n",
      "Sum 8459.050024032593\n"
     ]
    }
   ],
   "source": [
    "train_rewards, train_profits, test_rewards, test_profits = train_test_by_q(Environment1(train), Environment1(test), Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc8d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
